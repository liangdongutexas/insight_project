{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "493a8231a448b2727bc7d2eb2f995bf6a6b0c5eb"
   },
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "a1b737b2491d22b501f4d53c70ab811ce1ce8471"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'unicode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1da791bc8060>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'unicode'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, I will make the previous web scraping codes into a pipelin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. functionget_hyperlinks will created a csv file with the name: component_name_hyperlinks.csv. This file stores all the hyperlinks of each item in the search page of url from newegg website.\n",
    "\n",
    "   a. component_name is the name of the computer components i.e intel_cpu\n",
    "   \n",
    "   b. The url should be in the following form url = \"https://www.newegg.com/p/pl?N=100007671%20601306860&Page={}\"\n",
    "   \n",
    "   c. num_pages is the total number of pages to be web scraped in the searching page of the url at newegg website\n",
    "   \n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping all Hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperlinks(component_name,url,num_pages):\n",
    "    ## create a csv table to store all the hyperlinks of CPU\n",
    "    filename = \"{}_hyperlinks.csv\".format(component_name)\n",
    "    f = open(filename, \"w\", encoding='utf-8')\n",
    "    headers = \"price,product_detail,hyperlink\\n\"\n",
    "    f.write(headers)\n",
    "    \n",
    "    \n",
    "    # Scraping num_pages of my_url from newegg\n",
    "    print('Scraping {} searching pages:'.format(component_name))\n",
    "    \n",
    "    for i in range(1, num_pages+1):\n",
    "        my_url = url.format(i)\n",
    "        uClient = request.urlopen(my_url)\n",
    "        page_html = uClient.read()\n",
    "        uClient.close()\n",
    "        page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "        containers = page_soup.findAll(\"div\", {\"class\": \"item-container\"})\n",
    "\n",
    "        for container in containers:\n",
    "            ## Find hyperlink that directs to the webpage of that particular product\n",
    "            hyperlink = list(container.children)[3]['href']\n",
    "            ## discard data with bad format(will be revised in the future)\n",
    "            if not hyperlink:\n",
    "                continue\n",
    "            \n",
    "            ## find the current price of this item\n",
    "            Pli=container.find('li',{\"class\":\"price-current\"})\n",
    "\n",
    "            strong=Pli.find('strong')\n",
    "            sup=Pli.find('sup')\n",
    "            \n",
    "            strong=strong.text if strong else ''               \n",
    "            sup=sup.text if strong else ''\n",
    "\n",
    "            price=strong+sup\n",
    "            if price:\n",
    "                price=price.replace(',','')\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            ## find the product detail of the product\n",
    "            product_detail = list(container.children)[3].img[\"alt\"].replace(\",\", \"  \")\n",
    "            \n",
    "            \n",
    "            f.write(price+\",\"+product_detail+\",\"+hyperlink+\"\\n\")\n",
    "\n",
    "            time.sleep(random.random()+0.5)\n",
    "        time.sleep(10+random.random())\n",
    "        print(i)\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all specs from the hyperlink_file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specs_to_csv(Specs,component_name):\n",
    "## find the current header of the file if none set header to an empty list\n",
    "        with open(component_name+\"_specs.csv\", \"r\") as g:\n",
    "            reader = csv.reader(g)\n",
    "            try:\n",
    "                header=next(reader)\n",
    "            except:\n",
    "                header=list(Specs.keys())\n",
    "                with open(component_name+\"_specs.csv\", \"a\") as f:\n",
    "                    f.write(','.join(header))\n",
    "        \n",
    "        ## check whether current header is the same as the Specs.keys()\n",
    "        for col in Specs.keys():\n",
    "            if col not in header:\n",
    "            \n",
    "                ## use pandas to add a column with 'None' to the right\n",
    "                df = pd.read_csv(component_name+\"_specs.csv\")\n",
    "                new_column = pd.DataFrame({col: ['None' for i in range(len(df))]})\n",
    "                df = df.merge(new_column, left_index = True, right_index = True)\n",
    "                df.to_csv(component_name+\"_specs.csv\", index = False)\n",
    "                   \n",
    "                header.append(col)\n",
    "        \n",
    "        ## write the current Specs to the csv file\n",
    "        Specs_str=''\n",
    "        for col in header:\n",
    "            Specs_str=Specs_str+str(Specs.get(col,'None')).replace(',',' ')+','\n",
    "        Specs_str=Specs_str+'\\n'\n",
    "            \n",
    "        with open(component_name+\"_specs.csv\", \"a\") as f:\n",
    "            f.write(Specs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return a list of specs by webscraping all the hyperlinks in the \n",
    "#  component_name+\"_hyperlinks.csv\" file created by get_hyperlinks function \n",
    "#  start is the index of the starting hyperlink\n",
    "def write_specs(start,component_name):\n",
    "    hyperlinks=pd.read_csv(component_name+\"_hyperlinks.csv\")\n",
    "    \n",
    "    ## create a csv table to store all the specs of component if there is \n",
    "    ## no such file\n",
    "    filename = component_name+\"_specs.csv\"\n",
    "    with open(filename, \"a\")  as f:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## all cpu specs will be stored in the list total_specs\n",
    "    ## then total_specs will be stored in a csv table\n",
    "\n",
    "    i=0\n",
    "    print('Scraping each item page of {} for specs:'.format(component_name))\n",
    "    \n",
    "    # len(hyperlinks['hyperlink'])\n",
    "    for i in range(start,start+1):\n",
    "        url=hyperlinks['hyperlink'][i]\n",
    "        ## if the url cannot be open, continue\n",
    "        try:\n",
    "            uClient = request.urlopen(url)\n",
    "            page_html = uClient.read()\n",
    "            uClient.close()\n",
    "            page_soup = BeautifulSoup(page_html, \"html.parser\")\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        ## create a dict Specs to store the specification information of the item\n",
    "        try:\n",
    "            Specs={'price':hyperlinks['price'][i]}\n",
    "            \n",
    "            specs = page_soup.find(\"div\", {\"id\": \"Specs\"})\n",
    "            fieldsets=specs.findAll(\"fieldset\")\n",
    "                 \n",
    "            for fieldset in fieldsets:\n",
    "                dls=fieldset.findAll(\"dl\")\n",
    "                for dl in dls:\n",
    "                    Specs[dl.find(\"dt\").text]=dl.find(\"dd\").text          \n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        specs_to_csv(Specs,component_name)\n",
    "               \n",
    "        \n",
    "        i+=1\n",
    "        print(i)\n",
    "\n",
    "        time.sleep(10+random.random())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping each item page of AMD_MB for specs:\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xd7 in position 1: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d602c43cdc5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwrite_specs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AMD_MB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-3bd3ea2fa43b>\u001b[0m in \u001b[0;36mwrite_specs\u001b[1;34m(start, component_name)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mspecs_to_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSpecs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcomponent_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-57ecee8d84c7>\u001b[0m in \u001b[0;36mspecs_to_csv\u001b[1;34m(Specs, component_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[1;31m## use pandas to add a column with 'None' to the right\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_specs.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mnew_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'None'\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\programs\\envs\\tf-gpu-2.0\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\programs\\envs\\tf-gpu-2.0\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\programs\\envs\\tf-gpu-2.0\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\programs\\envs\\tf-gpu-2.0\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\programs\\envs\\tf-gpu-2.0\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xd7 in position 1: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "write_specs(1,'AMD_MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Specs_str='299.99,ASUS,ROG,STRIX X570-E GAMING,AM4,AMD AM4 Socket 3rd and 2nd AMD Ryzen / 2nd and 1st Gen AMD Ryzen with Radeon Vega Graphics Processors* Refer to www.asus.com for CPU support list,AMD X570,4×288pin,3rd Gen AMD Ryzen ProcessorsDDR4 4400(O.C.)/ 4266(O.C.)/ 4133(O.C.)/ 4000(O.C.)/ 3866(O.C.)/ 3600(O.C.)/ 3400(O.C.)/ 3200(O.C.)/ 3000(O.C.)/ 2800(O.C.)/ 2666/ 2400/ 2133 MHz Un-buffered Memory *2nd Gen AMD Ryzen ProcessorsDDR4 3600(O.C.)/ 3400(O.C.)/ 3200(O.C.)/ 3000(O.C.)/ 2800(O.C.)/ 2666/ 2400/ 2133 MHz Un-buffered Memory *2nd and 1st Gen AMD Ryzen with Radeon Vega Graphics ProcessorsDDR4 3200(O.C.)/ 3000(O.C.)/ 2800(O.C.)/ 2666/ 2400/ 2133 MHz Un-buffered Memory* Refer to www.asus.com for the Memory QVL (Qualified Vendors Lists).,128GB,Dual Channel,3rd Gen AMD Ryzen Processors2 x PCIe 4.0 x16 (x16 or dual x8)2nd Gen AMD Ryzen Processors2 x PCIe 3.0 x16 (x16 or dual x8)2nd and 1st Gen AMD Ryzen with Radeon Vega Graphics Processors1 x PCIe 3.0 x16 (x8 mode)AMD X570 chipset1 x PCIe 4.0 x16 (max at x4 mode) ** PCIeX16_3 slot shares bandwidth with PCIeX1_2.,2 x PCIe 4.0 x1,8 x SATA 6Gb/s,3rd Gen AMD Ryzen Processors:1 x M.2 Socket 3  with M Key  Type 2242/2260/2280/22110 (PCIE 4.0 x4 and SATA modes) storage devices support2nd Gen AMD Ryzen / 2nd and 1st Gen AMD Ryzen with Radeon Vega Graphics Processors:1 x M.2 Socket 3  with M Key  Type 2242/2260/2280/22110 (PCIE 3.0 x4 and SATA modes) storage devices supportAMD X570 chipset:1 x M.2 Socket 3  with M Key  Type 2242/2260/2280/22110 (PCIE 4.0 x4 and SATA modes) storage devices support,0/1/10,Integrated Graphics in the 2nd and 1st Gen AMD Ryzen with Radeon Vega Graphics ProcessorsMulti-VGA output support: HDMI/DisplayPort ports- Supports HDMI 2.0b with maximum resolution of 4096 x 2160 @ 60 Hz- Supports DisplayPort 1.2 with max. resolution 4096 x 2160 @ 60 Hz,SupremeFX High Definition Audio CODEC S1220A,8 Channels* Due to limitations in HDA bandwidth  32-Bit / 192 kHz is not supported for 8-Channel audio.,Realtek RTL8125-CG,Intel I211-AT,10/100/1000/2500Mbps + 10/100/1000Mbps,Supports channel bandwidth: HT20/HT40/HT80/HT160Intel Wi-Fi 6 AX2002 x 2 Wi-Fi 6 (802.11 a/b/g/n/ac/ax) with MU-MIMO supports dual frequency band 2.4/5 GHzUp to 2.4Gbps transfer speed,Bluetooth 5.0,1 x DisplayPort1 x HDMI1 x Optical S/PDIF out5 x Audio jack(s)1 x Anti-surge 2.5G LAN (RJ45) port1 x USB BIOS Flashback Button(s)1 x ASUS Wi-Fi Module7 x USB 3.2 Gen 2 (up to 10Gbps) ports (Type-A)1 x USB 3.2 Gen 2 (up to 10Gbps) ports (Type-C)Anti-surge LAN (RJ45) port,1 x USB 3.2 Gen 2 (up to 10Gbps) connector1 x USB 3.2 Gen 1 (up to 5Gbps) connector support additional 2 USB ports2 x USB 2.0 connector(s) support(s) additional 4 USB 2.0 port(s),1 x PCH_FAN1 x AAFP connector2 x Aura RGB Strip Header(s)2 x Addressable Gen 2 header(s)1 x SPI TPM header1 x CPU Fan connector(s)1 x CPU OPT Fan connector(s)2 x Chassis Fan connector(s)1 x AIO_PUMP connector1 x W_PUMP+ connector1 x Front panel audio connector(s) (AAFP)1 x Thermal sensor connector(s)1 x Clear CMOS jumper(s)1 x Node Connector(s)1 x System panel connector1 x T_Sensor Connector1 x M.2 Fan Header,ATX,RGB,12.0\" x 9.6\",1 x 24-pin EATX Power connector(s)1 x 8-pin ATX 12V Power connector(s)1 x 4-pin ATX 12V Power connector(s),Multi-GPU Support:3rd and 2nd Gen AMD Ryzen ProcessorsSupports NVIDIA 2-Way SLI TechnologySupports AMD 3-Way CrossFireX Technology2nd and 1st Gen AMD Ryzen with Radeon Vega Graphics ProcessorsSupports AMD 2-Way CrossFireX TechnologyROG Exclusive Features:ROG Exclusive Software- RAMCache III- CPU-Z- GameFirst V- Sonic Studio III + Sonic Studio Link- Sonic Radar III- OverwolfSpecial Features:5-Way Optimization by Dual Intelligent Processors 5- Whole system optimization with a single click! 5-Way Optimization tuning key perfectly consolidates TPU  EPU  DIGI+ VRM  Fan Xpert 4  and Turbo App together  providing better CPU performance  efficient power saving  precise digital power control  whole system cooling and even tailor your own app usagesTPU- Auto Tuning  TurboV  GPU BoostGamer\\'s Guardian:- DRAM Overcurrent Protection- Stainless Steel Back I/O- Highly Durable Components- DIGI+ VRM- SafeSlot- ESD Guards on LAN  Audio  and USB portsASUS EPU:- EPUAURA:- Aura Lighting Control- Addressable Gen 2 HeaderASUS Exclusive Features:- USB BIOS Flashback- AI Suite 3- Ai Charger- ASUS NODE: hardware control interface- BIOS Flashback ButtonASUS EZ DIY:- ASUS CrashFree BIOS 3- ASUS EZ Flash 3ASUS Q-Design:- ASUS Q-Code- ASUS Q-LED (CPU  DRAM  VGA  Boot Device LED)- ASUS Q-Slot- ASUS Q-DIMMGaming Aesthetics:- AURA-RGB LightingBIOS:256MB Flash ROM  UEFI AMI BIOS  PnP  WfM2.0  SM BIOS 3.2  ACPI 6.2Manageability:WOL  PXESupport Disc:OverwolfAnti-virus software (OEM version)WinRAROperating System:Windows 10 64-bit,Accessories:User\\'s manual4 x SATA 6Gb/s cable(s)1 x M.2 Screw Package1 x Supporting DVD1 x Strix door hanger1 x ROG Strix stickers1 x Cable ties pack(s)1 x Wi-Fi Antenna(s)1 x Extension Cable for RGB strips (80cm)1 x Extension cable for Addressable LED1 x Thermistor cable(s)1 x ROG Thank you card,July 07  2019,\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('AMD_MB'+\"_specs.csv\", \"a\") as f:\n",
    "    f.write(Specs_str)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## write all the specs into a csv file called component_name+\"_specs.csv\"\n",
    "def write_specs(total_specs,component_name):\n",
    "    ## find the maximal number of header titles for the csv file\n",
    "    headers=total_specs[0]\n",
    "    for i in total_specs[1:]:\n",
    "        for j in i.keys():\n",
    "            if j not in headers:\n",
    "                headers[j]=None    \n",
    "    \n",
    "    ## make a string file for the header\n",
    "    headerstr=''\n",
    "    for i in list(headers.keys()):\n",
    "        headerstr=headerstr+i+','\n",
    "    headerstr=headerstr+'\\n'      \n",
    "    \n",
    "    ## We create a csv table to store all the hyperlinks of CPU\n",
    "    filename = component_name+\"_specs.csv\"\n",
    "    f = open(filename, \"w\", encoding='utf-8')\n",
    "    f.write(headerstr)\n",
    "    \n",
    "    ## write specs information into the csv file\n",
    "    headers_list=list(headers.keys())\n",
    "    for item in total_specs:\n",
    "        item_str=''\n",
    "        for col in headers_list:\n",
    "            item_str=item_str+str(item.get(col,'None')).replace(',',' ')+','\n",
    "        item_str=item_str[:-1]\n",
    "        item_str=item_str+'\\n'\n",
    "        f.write(item_str) \n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here is the total pipeline\n",
    "def pipeline(component_name,url,num_pages):\n",
    "    get_hyperlinks(component_name,url,num_pages)\n",
    "    total_specs=get_specs(component_name)\n",
    "    write_specs(total_specs,component_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.newegg.com/AMD-Motherboards/SubCategory/ID-22/Page-{}'\n",
    "component_name='AMD_MB'\n",
    "num_pages=52 \n",
    "pipeline(component_name,url,num_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
