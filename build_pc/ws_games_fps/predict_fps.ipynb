{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this part is to fit the model to a sparse matrix with some games' FPS are missing. \n",
    "The key part is to compute the MSE with some element of F representing the fps data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model to predict FPS\n",
    "First, we build our modle as:\n",
    "\\begin{align} \n",
    "F^{i}_{mn}=g^{i}P_{mn}+\\alpha_{mn}\n",
    "\\end{align}\n",
    "where $i$ is the label for games, $mn$ are the label for gpu and cpu respectively, and $\\alpha$ contains other information that is game independent.\n",
    "\n",
    "Next, I will use the current data to testify this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters in this model is $i+2*m*n$.\n",
    "Because we find 'i' games fps benchmark, the number of data point will be $i*m*n$.\n",
    "In the case where $i=24,m=28,n=14$,the number of parameters are $808$ and the number of data points is $9408$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find2d returna a 2d array representing fps among \n",
    "## different cpu, gpu combinations given a game\n",
    "def find2d(game_name):\n",
    "    game_fps=pd.read_csv(game_name+'.csv')\n",
    "    game_fps=np.array(game_fps)\n",
    "    game_fps=[i[1:] for i in game_fps]\n",
    "    game_fps=np.array(game_fps).astype(np.float32)\n",
    "    return game_fps\n",
    "\n",
    "def load_fps_data():\n",
    "    game_names=pd.read_csv('games_fps_hyperlinks.csv')['game_name']\n",
    "    fps_all=np.array([find2d(i) for i in game_names])\n",
    "    print('The training data contains {} games tested,\\n'.format(fps_all.shape[0]), \n",
    "          '{} gpu types,'.format(fps_all.shape[1]), \n",
    "          '{} cpu types'.format(fps_all.shape[2]))\n",
    "    return fps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here I will use tensor flow to do it.\n",
    "class model():\n",
    "    def __init__(self):\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(24,)))\n",
    "        self.P=tf.Variable(tf.random.truncated_normal(shape=(28,14)))\n",
    "        self.alpha=tf.Variable(tf.random.truncated_normal(shape=(28,14)))\n",
    "        self.trainable_variables=[self.P,self.alpha,self.g]\n",
    "    def __call__(self):\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[i]*self.P,0) for i in range(24)],0)\\\n",
    "                    +tf.tile(tf.expand_dims(self.alpha,0),[24,1,1])\n",
    "        return F_predict\n",
    "    def load_variables(self,parameters,g):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.alpha=tf.constant(parameters[1])\n",
    "        if g:\n",
    "            self.g=tf.constant(parameters[2])\n",
    "        else:\n",
    "            self.g=tf.Variable(tf.random.truncated_normal(shape=(1,)))\n",
    "            self.trainable_variables=\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(F_predict, F):\n",
    "    count=0\n",
    "    SE=0\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            for k in range(F.shape[2]):\n",
    "                if F[i,j,k]:\n",
    "                    SE=SE+tf.math.square(F_predict[i,j,k]-F[i,j,k])\n",
    "                    count+=1   \n",
    "    return SE/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_one_step(model,F):\n",
    "    with tf.GradientTape() as tape:\n",
    "        F_predict = model()\n",
    "        loss = compute_loss(F_predict,F) \n",
    "        # compute gradient\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # update to weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "def build(model,epochs,F):   \n",
    "    for epoch in range(epochs):           \n",
    "        train_one_step(model,F)  \n",
    "        if epoch%10==0:\n",
    "            F_predict=model()\n",
    "            print('for epoch {}, MSE is {}'.format(epoch,compute_loss(F_predict,F)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel=model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=300\n",
    "build(testmodel,epochs,fps_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,path):\n",
    "    stored_variables=np.array([i.numpy() for i in model.trainable_variables])\n",
    "    np.save(path, stored_variables,allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predict(model,path,g=False):\n",
    "    parameters=np.load('savedmodel.npy',allow_pickle=True)\n",
    "    if g:\n",
    "        model.load_variables(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializer=[(fps,gpu_number,cpu_number),......]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,initializer):\n",
    "    if not initializer:\n",
    "        raise ValueError('initializer should not be empty')\n",
    "    else:\n",
    "        predict=[]\n",
    "        observe=[]\n",
    "        for test in initializer:\n",
    "            observe.append(test[0])\n",
    "            predict.append(model()[0][test[1]][test[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.Variable(tf.random.truncated_normal(shape=(1,28,14)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][12][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
