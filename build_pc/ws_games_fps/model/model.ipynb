{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this part is to fit the model to a sparse matrix with some games' FPS are missing. \n",
    "The key part is to compute the MSE with some element of F representing the fps data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model to predict FPS\n",
    "First, we build our modle as:\n",
    "\\begin{align} \n",
    "F^{i}_{mn}=g^{i}P_{mn}+\\alpha_{mn}\n",
    "\\end{align}\n",
    "where $i$ is the label for games, $mn$ are the label for gpu and cpu respectively, and $\\alpha$ contains other information that is game independent.\n",
    "\n",
    "Next, I will use the current data to testify this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a new model to predict FPS\n",
    "First, we build our modle as:\n",
    "\\begin{align} \n",
    "F^{i}_{mn}=g^{i}G_{m}C_{n}\n",
    "\\end{align}\n",
    "where $i$ is the label for games, $mn$ are the label for gpu and cpu respectively, and $\\alpha$ contains other information that is game independent.\n",
    "\n",
    "Next, I will use the current data to testify this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters in this model is $i+m+n$.\n",
    "Because we find 'i' games fps benchmark, the number of data point will be $i*m*n$.\n",
    "In the case where $i=24,m=28,n=14$,the number of parameters are $66$ and the number of data points is $9408$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell is the model class. \n",
    "Its __call__ method returns the predicted FPS according to aformentioned formula.\n",
    "Its load_variables method loads previously trained parameters which will be used by the __call__ method to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## i is the total number of games, m is the total number of GPUs considered,\n",
    "## and n is th total number of CPUs considered.\n",
    "class model():\n",
    "    def __init__(self,shape):\n",
    "        self.i=shape[0]\n",
    "        self.m=shape[1]\n",
    "        self.n=shape[2]\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(self.i,)))\n",
    "        self.P=tf.Variable(tf.random.truncated_normal(shape=(self.m,self.n)))\n",
    "        self.alpha=tf.Variable(tf.random.truncated_normal(shape=(self.m,self.n)))\n",
    "        self.trainable_variables=[self.P,self.alpha,self.g]\n",
    "        \n",
    "    def __call__(self):\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[j]*self.P,0) for j in range(self.i)],0)\\\n",
    "                    +tf.tile(tf.expand_dims(self.alpha,0),[self.i,1,1])\n",
    "        return F_predict\n",
    "    \n",
    "    def load_variables(self,parameters):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.alpha=tf.constant(parameters[1])\n",
    "        self.g=tf.constant(parameters[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model without alpha\n",
    "class model_without_alpha():\n",
    "    def __init__(self,shape):\n",
    "        self.i=shape[0]\n",
    "        self.m=shape[1]\n",
    "        self.n=shape[2]\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(self.i,)))\n",
    "        self.P=tf.Variable(tf.random.truncated_normal(shape=(self.m,self.n)))\n",
    "        self.trainable_variables=[self.P,self.g]\n",
    "        \n",
    "    def __call__(self):\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[j]*self.P,0) for j in range(self.i)],0)\n",
    "        return F_predict\n",
    "    \n",
    "    def load_variables(self,parameters):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.g=tf.constant(parameters[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model that also decomposes GPU and CPU\n",
    "class model_cpu_gpu():\n",
    "    def __init__(self,shape):\n",
    "        self.i=shape[0]\n",
    "        self.m=shape[1]\n",
    "        self.n=shape[2]\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(self.i,)))\n",
    "        self.G=tf.Variable(tf.random.truncated_normal(shape=(self.m,)))\n",
    "        self.C=tf.Variable(tf.random.truncated_normal(shape=(self.n,)))\n",
    "        self.trainable_variables=[self.G,self.C,self.g]\n",
    "        \n",
    "    def __call__(self):\n",
    "        P=tf.concat([tf.expand_dims(self.G[j]*self.C,0) for j in range(self.m)],0)\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[j]*P,0) for j in range(self.i)],0)\n",
    "        return F_predict\n",
    "    \n",
    "    def load_variables(self,parameters):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.g=tf.constant(parameters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we defien a pipeline to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main pipeline. It takes the model, the epochs and training data F. \n",
    "F is a np array with dimension (games,GPU,CPU).\n",
    "Non-tested FPS in the training data F should be denoted by np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,F,savepath,epochs=300): \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "    for epoch in range(epochs):           \n",
    "        train_one_step(model,F,optimizer)  \n",
    "        if epoch%10==0:\n",
    "            F_predict=model()\n",
    "            print('for epoch {}, MSE is {}'.format(epoch,compute_loss_sparse(F_predict,F)))\n",
    "    save_model(model,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses tensorflow to do backpropagation onece for each epoch.\n",
    "def train_one_step(model,F,optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        F_predict = model()\n",
    "        loss=compute_loss_sparse(F_predict, F)\n",
    "        # compute gradient\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # update to weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computes the mean squared error of predicted FPS with respect to the real FPS at those tested data point in F.  \n",
    "def compute_loss_sparse(F_predict, F):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    indices_true,indices_false=cal_indices(F)\n",
    "    \n",
    "    ## if there is no None data or missing data in F, return a normal mse\n",
    "    ## else return mse based on the given data\n",
    "    if not indices_false:\n",
    "        return mse(F_predict,F) \n",
    "    else:\n",
    "        F=tf.constant(F)    \n",
    "        return mse(tf.gather_nd(F_predict,indices_true),tf.gather_nd(F,indices_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indices_true is where FPS test is given \n",
    "## indices_false is where FPS test is missing\n",
    "def cal_indices(F):\n",
    "    indices_true=[]\n",
    "    indices_false=[]\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            for k in range(F.shape[2]):\n",
    "                if np.isnan(F[i,j,k]):\n",
    "                    indices_false.append([i,j,k])\n",
    "                else:\n",
    "                    indices_true.append([i,j,k])\n",
    "    return indices_true, indices_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,path):\n",
    "    stored_variables=np.array([i.numpy() for i in model.trainable_variables])\n",
    "    np.save(path, stored_variables,allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we will load the data and take part of the data as validation set.\n",
    "The format of the data will be numpy.array with shape (i,m,n), with i the game label, m the GPU label, and n the CPU label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_np():\n",
    "    cwd = os.getcwd()\n",
    "    cwd='/'.join(cwd.split('/')[:-1])\n",
    "    path=cwd+'/tested_data/games_fps_cpu_gpu.db'\n",
    "    \n",
    "    cnx = sqlite3.connect(path)\n",
    "    c=cnx.cursor()\n",
    "    Game_Name=c.execute('''SELECT DISTINCT Game_Name FROM games_fps''').fetchall()\n",
    "\n",
    "    Game_Name=[i[0] for i in Game_Name]\n",
    "    GPU=[i[0] for i in GPU]\n",
    "    CPU=[i[0] for i in CPU]\n",
    "\n",
    "    total=[]\n",
    "    for game in Game_Name:\n",
    "        result=pd.read_sql('''SELECT GPU,CPU,FPS FROM games_fps where Game_Name='{}' '''.format(game),cnx)\n",
    "        result=result.pivot(index='GPU', columns='CPU', values='FPS')\n",
    "        result=result.sort_index()\n",
    "        result=result.reindex(sorted(result.columns), axis=1)\n",
    "        total.append(result.to_numpy())\n",
    "\n",
    "    total=np.array(total)\n",
    "\n",
    "    cnx.commit()\n",
    "    c.close()\n",
    "    cnx.close()\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 28, 14)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find2d return a 2d array representing fps among \n",
    "## different cpu, gpu combinations for a fixed game\n",
    "def find2d(game_name):\n",
    "    game_fps=pd.read_csv(game_name+'.csv')\n",
    "    game_fps=np.array(game_fps)\n",
    "    game_fps=[i[1:] for i in game_fps]\n",
    "    game_fps=np.array(game_fps).astype(np.float32)\n",
    "    return game_fps\n",
    "\n",
    "def load_fps_data():\n",
    "    game_names=pd.read_csv('games_fps_hyperlinks.csv')['game_name']\n",
    "    fps_all=np.array([find2d(i) for i in game_names])\n",
    "    print('The training data contains {} games tested,\\n'.format(fps_all.shape[0]), \n",
    "          '{} gpu types,'.format(fps_all.shape[1]), \n",
    "          '{} cpu types'.format(fps_all.shape[2]))\n",
    "    return fps_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly set N data in F to be None and return the missing data indices\n",
    "def setzero(F,N):\n",
    "    indices=[]\n",
    "    F_missing=np.copy(F)\n",
    "    shape=F.shape\n",
    "    for i in range(N):\n",
    "        indices.append([random.randint(0,shape[0]-1),random.randint(0,shape[1]-1),random.randint(0,shape[2]-1)])    \n",
    "    for i,j,k in indices:\n",
    "        F_missing[i,j,k]=None\n",
    "    \n",
    "    return indices,F_missing     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(indices,model,F):\n",
    "    mse=tf.keras.losses.MeanSquaredError()\n",
    "    F_predict=model()  \n",
    "    return mse(tf.gather_nd(F_predict,indices),tf.gather_nd(F,indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pipeline that discard N training data and train a model on the processed data\n",
    "def valid_pipeline(N):\n",
    "    F=load_fps_data()\n",
    "    testmodel=model_cpu_gpu(F.shape)\n",
    "    ## create some missing data manually\n",
    "    indices,F_missing=setzero(F,N)\n",
    "    i,j,k=F.shape\n",
    "    print('\\n','The number of training data is {} out of {} \\n'.format(np.count_nonzero(~np.isnan(F_missing)),i*j*k))\n",
    "    ## use the missing data to train the model and save the model\n",
    "    train_model(testmodel,F_missing,'savedmodel')\n",
    "    ## print out the validation accuracy\n",
    "    print('\\n','The validation MSE is {}'.format(tf.keras.backend.get_value(validation(indices, testmodel,F))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data contains 24 games tested,\n",
      " 28 gpu types, 14 cpu types\n",
      "\n",
      " The number of training data is 3244 out of 9408 \n",
      "\n",
      "for epoch 0, MSE is 11633.25390625\n",
      "for epoch 10, MSE is 11560.9765625\n",
      "for epoch 20, MSE is 10882.68359375\n",
      "for epoch 30, MSE is 8228.2333984375\n",
      "for epoch 40, MSE is 4202.56640625\n",
      "for epoch 50, MSE is 1544.2957763671875\n",
      "for epoch 60, MSE is 454.0294494628906\n",
      "for epoch 70, MSE is 143.18777465820312\n",
      "for epoch 80, MSE is 43.316951751708984\n",
      "for epoch 90, MSE is 14.380014419555664\n",
      "for epoch 100, MSE is 6.280126571655273\n",
      "for epoch 110, MSE is 2.0478708744049072\n",
      "for epoch 120, MSE is 0.7865241765975952\n",
      "for epoch 130, MSE is 0.3017795979976654\n",
      "for epoch 140, MSE is 0.13132977485656738\n",
      "for epoch 150, MSE is 0.05146137624979019\n",
      "for epoch 160, MSE is 0.03429296985268593\n",
      "for epoch 170, MSE is 0.028801994398236275\n",
      "for epoch 180, MSE is 0.025604140013456345\n",
      "for epoch 190, MSE is 0.02415713667869568\n",
      "for epoch 200, MSE is 0.024025723338127136\n",
      "for epoch 210, MSE is 0.023909011855721474\n",
      "for epoch 220, MSE is 0.0238629262894392\n",
      "for epoch 230, MSE is 0.023844877257943153\n",
      "for epoch 240, MSE is 0.02384091727435589\n",
      "for epoch 250, MSE is 0.02383957989513874\n",
      "for epoch 260, MSE is 0.023838767781853676\n",
      "for epoch 270, MSE is 0.023838555440306664\n",
      "for epoch 280, MSE is 0.023838475346565247\n",
      "for epoch 290, MSE is 0.0238384660333395\n",
      "\n",
      " The validation MSE is 0.028503302484750748\n"
     ]
    }
   ],
   "source": [
    "valid_pipeline(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "G,C,g=np.load('savedmodel.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=abs(G)\n",
    "C=abs(C)\n",
    "g=abs(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=g*max(G)*max(C)/(10000)\n",
    "G=(G/max(G))*100\n",
    "C=(C/max(C))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 54.790993,  68.70181 ,  51.418213, 105.09394 ,  82.19783 ,\n",
       "        49.767143,  28.36716 ,  57.85394 ,  42.797348,  65.78896 ,\n",
       "        54.470993,  53.646492,  83.26474 ,  31.391153,  44.04533 ,\n",
       "        44.72377 ,  84.23137 ,  74.925   ,  71.426605,  53.308975,\n",
       "        46.95886 ,  91.00462 ,  41.15585 , 100.87287 ], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predict(model,path):\n",
    "    parameters=np.load('savedmodel.npy',allow_pickle=True)\n",
    "    model.load_variables(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializer=[(fps,gpu_number,cpu_number),......]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
