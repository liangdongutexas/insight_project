{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this part is to fit the model to a sparse matrix with some games' FPS are missing. \n",
    "The key part is to compute the MSE with some element of F representing the fps data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a model to predict FPS\n",
    "First, we build our modle as:\n",
    "\\begin{align} \n",
    "F^{i}_{mn}=g^{i}P_{mn}+\\alpha_{mn}\n",
    "\\end{align}\n",
    "where $i$ is the label for games, $mn$ are the label for gpu and cpu respectively, and $\\alpha$ contains other information that is game independent.\n",
    "\n",
    "Next, I will use the current data to testify this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a new model to predict FPS\n",
    "First, we build our modle as:\n",
    "\\begin{align} \n",
    "F^{i}_{mn}=g^{i}G_{m}C_{n}\n",
    "\\end{align}\n",
    "where $i$ is the label for games, $mn$ are the label for gpu and cpu respectively, and $\\alpha$ contains other information that is game independent.\n",
    "\n",
    "Next, I will use the current data to testify this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of parameters in this model is $i+m+n$.\n",
    "Because we find 'i' games fps benchmark, the number of data point will be $i*m*n$.\n",
    "In the case where $i=24,m=28,n=14$,the number of parameters are $66$ and the number of data points is $9408$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The motivation to build this model is based on the following observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total,Game_Name,GPU,CPU=sql_to_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 28, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f4556826b10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig,ax=plt.subplots(3,3)\n",
    "\n",
    "row=ax[0]\n",
    "for j in range(len(row)):\n",
    "    pos=row[j].imshow(total[j,:,:],cmap='plasma',aspect='auto')\n",
    "    row[j].set_title('game_{}'.format(j))\n",
    "fig.colorbar(pos,ax=ax[0])\n",
    "\n",
    "row=ax[1]\n",
    "for j in range(len(row)):\n",
    "    row[j].imshow(total[:,j,:],cmap='plasma',aspect='auto')\n",
    "    row[j].set_title('gpu_{}'.format(j))\n",
    "fig.colorbar(pos,ax=ax[1])\n",
    "\n",
    "row=ax[2]\n",
    "for j in range(len(row)):\n",
    "    row[j].imshow(total[:,:,j],cmap='plasma',aspect='auto')\n",
    "    row[j].set_title('cpu_{}'.format(j))\n",
    "fig.colorbar(pos,ax=ax[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f8dd4f9f510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax=plt.subplots(2)\n",
    "\n",
    "for j in range(len(ax)):\n",
    "    pos=ax[j].imshow(total[j,:,:],cmap='plasma',aspect='auto')\n",
    "    ax[j].set_title('game_{}'.format(j))\n",
    "fig.colorbar(pos,ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cell is the model class. \n",
    "Its __call__ method returns the predicted FPS according to aformentioned formula.\n",
    "Its load_variables method loads previously trained parameters which will be used by the __call__ method to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## i is the total number of games, m is the total number of GPUs considered,\n",
    "## and n is th total number of CPUs considered.\n",
    "class model():\n",
    "    def __init__(self,shape):\n",
    "        self.i=shape[0]\n",
    "        self.m=shape[1]\n",
    "        self.n=shape[2]\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(self.i,)))\n",
    "        self.P=tf.Variable(tf.random.truncated_normal(shape=(self.m,self.n)))\n",
    "        self.alpha=tf.Variable(tf.random.truncated_normal(shape=(self.m,self.n)))\n",
    "        self.trainable_variables=[self.P,self.alpha,self.g]\n",
    "        \n",
    "    def __call__(self):\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[j]*self.P,0) for j in range(self.i)],0)\\\n",
    "                    +tf.tile(tf.expand_dims(self.alpha,0),[self.i,1,1])\n",
    "        return F_predict\n",
    "    \n",
    "    def load_variables(self,parameters):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.alpha=tf.constant(parameters[1])\n",
    "        self.g=tf.constant(parameters[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model without alpha\n",
    "class model_without_alpha():\n",
    "    def __init__(self,shape):\n",
    "        self.i=shape[0]\n",
    "        self.m=shape[1]\n",
    "        self.n=shape[2]\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(self.i,)))\n",
    "        self.P=tf.Variable(tf.random.truncated_normal(shape=(self.m,self.n)))\n",
    "        self.trainable_variables=[self.P,self.g]\n",
    "        \n",
    "    def __call__(self):\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[j]*self.P,0) for j in range(self.i)],0)\n",
    "        return F_predict\n",
    "    \n",
    "    def load_variables(self,parameters):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.g=tf.constant(parameters[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model that also decomposes GPU and CPU\n",
    "class model_cpu_gpu():\n",
    "    def __init__(self,shape):\n",
    "        self.i=shape[0]\n",
    "        self.m=shape[1]\n",
    "        self.n=shape[2]\n",
    "        self.g=tf.Variable(tf.random.truncated_normal(shape=(self.i,)))\n",
    "        self.G=tf.Variable(tf.random.truncated_normal(shape=(self.m,)))\n",
    "        self.C=tf.Variable(tf.random.truncated_normal(shape=(self.n,)))\n",
    "        self.trainable_variables=[self.G,self.C,self.g]\n",
    "        \n",
    "    def __call__(self):\n",
    "        P=tf.concat([tf.expand_dims(self.G[j]*self.C,0) for j in range(self.m)],0)\n",
    "        F_predict=tf.concat([tf.expand_dims(self.g[j]*P,0) for j in range(self.i)],0)\n",
    "        return F_predict\n",
    "    \n",
    "    def load_variables(self,parameters):\n",
    "        self.P=tf.constant(parameters[0])\n",
    "        self.g=tf.constant(parameters[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next we defien a pipeline to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main pipeline. It takes the model, the epochs and training data F. \n",
    "F is a np array with dimension (games,GPU,CPU).\n",
    "Non-tested FPS in the training data F should be denoted by np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,F,savepath,epochs=200): \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "    for epoch in range(epochs):           \n",
    "        train_one_step(model,F,optimizer)  \n",
    "        if epoch%10==0:\n",
    "            F_predict=model()\n",
    "            print('for epoch {}, MSE is {}'.format(epoch,compute_loss_sparse(F_predict,F)))\n",
    "    save_model(model,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uses tensorflow to do backpropagation onece for each epoch.\n",
    "def train_one_step(model,F,optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        F_predict = model()\n",
    "        loss=compute_loss_sparse(F_predict, F)\n",
    "        # compute gradient\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # update to weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computes the mean squared error of predicted FPS with respect to the real FPS at those tested data point in F.  \n",
    "def compute_loss_sparse(F_predict, F):\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    indices_true,indices_false=cal_indices(F)\n",
    "    \n",
    "    ## if there is no None data or missing data in F, return a normal mse\n",
    "    ## else return mse based on the given data\n",
    "    if not indices_false:\n",
    "        return mse(F_predict,F) \n",
    "    else:\n",
    "        F=tf.constant(F)    \n",
    "        return mse(tf.gather_nd(F_predict,indices_true),tf.gather_nd(F,indices_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## indices_true is where FPS test is given \n",
    "## indices_false is where FPS test is missing\n",
    "def cal_indices(F):\n",
    "    indices_true=[]\n",
    "    indices_false=[]\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            for k in range(F.shape[2]):\n",
    "                if np.isnan(F[i,j,k]):\n",
    "                    indices_false.append([i,j,k])\n",
    "                else:\n",
    "                    indices_true.append([i,j,k])\n",
    "    return indices_true, indices_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,path):\n",
    "    stored_variables=np.array([i.numpy() for i in model.trainable_variables])\n",
    "    np.save(path, stored_variables,allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we will load the data and take part of the data as validation set.\n",
    "The format of the data will be numpy.array with shape (i,m,n), with i the game label, m the GPU label, and n the CPU label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load fps data from data base to np.array file\n",
    "def sql_to_np():\n",
    "    cwd = os.getcwd()\n",
    "    cwd='/'.join(cwd.split('/')[:-1])\n",
    "    if cwd:\n",
    "        path=cwd+'/tested_data/games_fps_cpu_gpu.db'\n",
    "    else:\n",
    "        cwd = os.getcwd()\n",
    "        cwd='\\\\'.join(cwd.split('\\\\')[:-1])\n",
    "        path=cwd+'\\\\tested_data\\\\games_fps_cpu_gpu.db'\n",
    "    \n",
    "    cnx = sqlite3.connect(path)\n",
    "    c=cnx.cursor()\n",
    "    Game_Name=c.execute('''SELECT DISTINCT Game_Name FROM games_fps''').fetchall()\n",
    "\n",
    "    Game_Name=[i[0] for i in Game_Name]\n",
    "\n",
    "\n",
    "    total=[]\n",
    "    GPU=[]\n",
    "    CPU=[]\n",
    "    for game in Game_Name:\n",
    "        result=pd.read_sql('''SELECT GPU,CPU,FPS FROM games_fps where Game_Name='{}' '''.format(game),cnx)\n",
    "        result=result.pivot(index='GPU', columns='CPU', values='FPS')\n",
    "        result=result.sort_index()\n",
    "        result=result.reindex(sorted(result.columns), axis=1)\n",
    "        if len(GPU)==0:\n",
    "            GPU=result.index         \n",
    "        if len(CPU)==0:\n",
    "            CPU=result.columns\n",
    "        total.append(result.to_numpy())\n",
    "\n",
    "    total=np.array(total)\n",
    "\n",
    "    cnx.commit()\n",
    "    c.close()\n",
    "    cnx.close()\n",
    "    \n",
    "    return total,Game_Name,GPU,CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## randomly set N data in F to be None and return the missing data indices\n",
    "def setzero(F,N):\n",
    "    indices=[]\n",
    "    F_missing=np.copy(F)\n",
    "    shape=F.shape\n",
    "    for i in range(N):\n",
    "        indices.append([random.randint(0,shape[0]-1),random.randint(0,shape[1]-1),random.randint(0,shape[2]-1)])    \n",
    "    for i,j,k in indices:\n",
    "        F_missing[i,j,k]=None\n",
    "    \n",
    "    return indices,F_missing     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(indices,model,F):\n",
    "    mse=tf.keras.losses.MeanSquaredError()\n",
    "    F_predict=model()  \n",
    "    return mse(tf.gather_nd(F_predict,indices),tf.gather_nd(F,indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_to_database(F_predict,Game_Name,GPU,CPU):\n",
    "    total=pd.DataFrame(columns=['CPU','GPU','FPS'])\n",
    "    for i in range(len(Game_Name)):\n",
    "        game_fps=pd.DataFrame(data=F_predict[i], index=GPU,  columns=CPU)\n",
    "        game_fps=game_fps.unstack().reset_index().rename(columns={0:'FPS'})\n",
    "        game_fps['Game_Name']=Game_Name[i]\n",
    "        total=total.append(game_fps)\n",
    "    total.reset_index(drop=True)\n",
    "\n",
    "    ## get the path of prediction_data file\n",
    "    cwd = os.getcwd()\n",
    "    cwd='/'.join(cwd.split('/')[:-1])\n",
    "    if cwd:\n",
    "        path=cwd+'/prediction_data/games_fps_cpu_gpu.db'\n",
    "    else:\n",
    "        cwd = os.getcwd()\n",
    "        cwd='\\\\'.join(cwd.split('\\\\')[:-1])\n",
    "        path=cwd+'\\\\prediction_data\\\\games_fps_cpu_gpu.db'\n",
    "    \n",
    "    ## store data to database\n",
    "    cnx = sqlite3.connect(path)\n",
    "    \n",
    "    try:\n",
    "        c=cnx.cursor()\n",
    "        c.execute('''DROP Table games_fps ''')\n",
    "        c.close()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    total.to_sql(name='games_fps',con=cnx)\n",
    "\n",
    "    cnx.commit()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_pred():\n",
    "    ## get the path of prediction_data file\n",
    "    cwd = os.getcwd()\n",
    "    cwd='/'.join(cwd.split('/')[:-1])\n",
    "    if cwd:\n",
    "        path_out=cwd+'/prediction_data/games_fps_cpu_gpu.db'\n",
    "    else:\n",
    "        cwd = os.getcwd()\n",
    "        cwd='\\\\'.join(cwd.split('\\\\')[:-1])\n",
    "        path_out=cwd+'\\\\prediction_data\\\\games_fps_cpu_gpu.db'\n",
    "\n",
    "    if cwd:\n",
    "        path_in=cwd+'/tested_data/games_fps_cpu_gpu.db'\n",
    "    else:\n",
    "        cwd = os.getcwd()\n",
    "        cwd='\\\\'.join(cwd.split('\\\\')[:-1])\n",
    "        path_in=cwd+'\\\\tested_data\\\\games_fps_cpu_gpu.db'\n",
    "        \n",
    "    ## store cpu gpu price information to to database\n",
    "    cnx = sqlite3.connect(path_in)\n",
    "    cpu_price=pd.read_sql('''SELECT * FROM cpu_price  ''',cnx).drop('index',axis=1)\n",
    "    gpu_price=pd.read_sql('''SELECT * FROM gpu_price  ''',cnx).drop('index',axis=1)\n",
    "    cnx.commit()\n",
    "    cnx.close()\n",
    "\n",
    "    cnx = sqlite3.connect(path_out)\n",
    "    try:\n",
    "        c=cnx.cursor()\n",
    "        c.execute('''DROP Table cpu_price ''')\n",
    "        c.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        c=cnx.cursor()\n",
    "        c.execute('''DROP Table gpu_price ''')\n",
    "        c.close()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cpu_price.to_sql(name='cpu_price',con=cnx)\n",
    "    gpu_price.to_sql(name='gpu_price',con=cnx)\n",
    "\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pipeline that train the model\n",
    "# when N=0 it just train the model with existing datat\n",
    "# else it uses N data as validation data and train the model with\n",
    "# the rest of the data \n",
    "def train_valid_pipeline(N=0):\n",
    "    F,Game_Name,GPU,CPU=sql_to_np()\n",
    "    testmodel=model_cpu_gpu(F.shape)\n",
    "    \n",
    "    if N!=0:\n",
    "        ## create some missing data\n",
    "        indices,F_missing=setzero(F,N)\n",
    "        i,j,k=F.shape    \n",
    "        print('\\n','The number of training data is {} out of {} \\n'.format(np.count_nonzero(~np.isnan(F_missing)),i*j*k))\n",
    "        ## use the missing data to train the model and save the model\n",
    "        train_model(testmodel,F_missing,'savedmodel')\n",
    "        \n",
    "        ## print out the validation accuracy\n",
    "        print('\\n','The validation MSE is {}'.format(tf.keras.backend.get_value(validation(indices, testmodel,F))))\n",
    "    \n",
    "    else:\n",
    "        train_model(testmodel,F,'savedmodel')\n",
    "        F_model=testmodel()\n",
    "        F_predict=np.copy(F)\n",
    "        ##  substituet the nan value in F with the value predicted by model\n",
    "        F_predict[np.isnan(F)]=F_model[np.isnan(F)]\n",
    "        # save the predicted value \n",
    "        pred_to_database(F_predict,Game_Name,GPU,CPU)\n",
    "        test_to_pred()\n",
    "        print('Prediction Data has been written in SQL format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch 0, MSE is 11484.09765625\n",
      "for epoch 10, MSE is 11437.236328125\n",
      "for epoch 20, MSE is 10673.23828125\n",
      "for epoch 30, MSE is 7618.95751953125\n",
      "for epoch 40, MSE is 2949.20263671875\n",
      "for epoch 50, MSE is 991.8280029296875\n",
      "for epoch 60, MSE is 112.13704681396484\n",
      "for epoch 70, MSE is 110.47969818115234\n",
      "for epoch 80, MSE is 29.03653335571289\n",
      "for epoch 90, MSE is 7.9740753173828125\n",
      "for epoch 100, MSE is 5.341856956481934\n",
      "for epoch 110, MSE is 1.460685133934021\n",
      "for epoch 120, MSE is 0.36119166016578674\n",
      "for epoch 130, MSE is 0.2379055768251419\n",
      "for epoch 140, MSE is 0.08324118703603745\n",
      "for epoch 150, MSE is 0.051862239837646484\n",
      "for epoch 160, MSE is 0.03428893908858299\n",
      "for epoch 170, MSE is 0.02801823616027832\n",
      "for epoch 180, MSE is 0.02748306654393673\n",
      "for epoch 190, MSE is 0.026466520503163338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\programs\\envs\\tf-gpu-2.0\\lib\\site-packages\\pandas\\core\\frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Data has been written in SQL format\n"
     ]
    }
   ],
   "source": [
    "train_valid_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
